{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading store:   0%|          | 0/366 [00:00<?, ?chunks/s]C:\\Users\\Abunch\\AppData\\Local\\Temp\\ipykernel_30152\\1579476883.py:300: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df.to_sql(table_name, conn, if_exists='append', index=False)\n",
      "Loading store:   0%|          | 0/366 [00:00<?, ?chunks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data into table `store`: Execution failed on sql '\n",
      "        SELECT\n",
      "            name\n",
      "        FROM\n",
      "            sqlite_master\n",
      "        WHERE\n",
      "            type IN ('table', 'view')\n",
      "            AND name=?;\n",
      "        ': Not all parameters were used in the SQL statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import requests\n",
    "from mysql.connector.connection import MySQLConnection\n",
    "from typing import Dict,List,Tuple,Any,Optional\n",
    "import shutil\n",
    "import py7zr  # For handling .7z files\n",
    "import zipfile\n",
    "from tqdm import tqdm # progress bar for download\n",
    "\n",
    "# Connection Variables\n",
    "USER = 'Sudo'\n",
    "PASSWORD = 'password'\n",
    "DATABASE = 'sys' # Do not change! This is the default database for MySQL\n",
    "\n",
    "\n",
    "#Server Connection Configuration\n",
    "CONN_CONFIG: Dict[str, str]  = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"user\": USER,\n",
    "    \"password\": PASSWORD,\n",
    "    \"database\": DATABASE\n",
    "}\n",
    "\n",
    "CONTOSO_DOWNLOAD_LINK = r\"https://github.com/sql-bi/Contoso-Data-Generator-V2-Data/releases/download/ready-to-use-data/csv-10m.7z\"\n",
    "CONTOSO_FILENAME = \"csv-10m.7z\"# DO NOT CHANGE THIS VALUE!\n",
    "\n",
    "DBSTART = 'Contoso' # Name of the database to create and where all other tables will be created\n",
    "EXTRACT_DIR = f\"{os.path.expanduser('~')}\\\\Downloads\\\\{DBSTART}\\\\\"\n",
    "\n",
    "\n",
    "def download_file(url: str, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads a file from a given URL and saves it to the user's Downloads folder,\n",
    "    with a progress bar displayed in the console.\n",
    "\n",
    "    :param url: The URL of the file to download.\n",
    "    :param filename: The name of the file to save.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    user_downloads_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "    file_path = os.path.join(user_downloads_dir, filename)\n",
    "\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx or 5xx)\n",
    "\n",
    "        # Get the total file size from the headers\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "\n",
    "        with open(file_path, 'wb') as f:\n",
    "            with tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Downloading\") as progress_bar:\n",
    "                for chunk in response.iter_content(chunk_size=1024):  # Download in 1KB chunks\n",
    "                    f.write(chunk)\n",
    "                    progress_bar.update(len(chunk))  # Update the progress bar\n",
    "\n",
    "    print(f\"File downloaded to: {file_path}\")\n",
    "\n",
    "\n",
    "def extract_archive(filename: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Searches for a given .7z archive file in the user's Downloads folder,\n",
    "    and extracts its contents to DOWNLOADS_DIR with a progress bar and detailed error handling.\n",
    "\n",
    "    :param filename: The name of the .7z archive file to extract.\n",
    "    :return: The path where files were extracted or None if extraction failed.\n",
    "    \"\"\"\n",
    "    user_downloads_dir = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "    file_path = os.path.join(user_downloads_dir, filename)\n",
    "\n",
    "    # Check if the file exists in Downloads folder\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File '{filename}' not found in {user_downloads_dir}.\")\n",
    "        return None\n",
    "\n",
    "    # Ensure the extraction directory exists\n",
    "    os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
    "\n",
    "    try:    \n",
    "        if filename.endswith(\".7z\"):\n",
    "            # Extract .7z files with a progress bar\n",
    "            try:\n",
    "                counter = 0 \n",
    "                with py7zr.SevenZipFile(file_path, mode='r', blocksize=1024*1024 ) as archive:\n",
    "                    file_list = archive.getnames()\n",
    "                    \n",
    "                    with tqdm(total=len(file_list), unit=\"Files Extracted\", desc=\"Extracting\") as  files_progress_bar:\n",
    "                \n",
    "                        for file in file_list:\n",
    "                            try:\n",
    "                                files_progress_bar.set_description(f\"Extracting {file}...\")\n",
    "                                files_progress_bar.refresh()\n",
    "                                archive.extract(targets=[os.path.join(user_downloads_dir,CONTOSO_FILENAME),file], path=EXTRACT_DIR, recursive=False)\n",
    "                                archive.reset() \n",
    "                                files_progress_bar.update(1)\n",
    "                                \n",
    "                            except Exception as file_error:\n",
    "                                print(f\"Error extracting file '{file}': {file_error}\")\n",
    "                                continue\n",
    "                            \n",
    "                            counter += 1\n",
    "                            if counter == len(file_list):\n",
    "                                archive.close()\n",
    "                                break\n",
    "                \n",
    "                print(f\"Extracted '{filename}' to '{EXTRACT_DIR}'.\")\n",
    "                return EXTRACT_DIR\n",
    "           \n",
    "            except py7zr.Bad7zFile:\n",
    "                print(f\"Error: '{filename}' is not a valid 7z file.\")\n",
    "                return None\n",
    "           \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting 7z file '{filename}': {e}\")\n",
    "                return None\n",
    "\n",
    "        else:\n",
    "            print(f\"Error: '{filename}' is not a supported archive format (7z).\")\n",
    "            return None\n",
    "\n",
    "    except PermissionError:\n",
    "        print(f\"Error: Permission denied while accessing '{filename}' or writing to '{EXTRACT_DIR}'.\")\n",
    "        return None\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found during extraction.\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error while extracting '{filename}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_database(db_name: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Creates a new MySQL database if it does not exist.\n",
    "\n",
    "    :param db_name: Name of the database to create.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MySQL Server (without specifying a database)\n",
    "        conn: MySQLConnection = mysql.connector.connect(**CONN_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Create database if it doesn't exist\n",
    "        cursor.execute(f\"CREATE DATABASE IF NOT EXISTS `{db_name}`;\")\n",
    "        print(f\"Database `{db_name}` created or already exists.\")\n",
    "\n",
    "        # Close connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "\n",
    "def infer_mysql_dtype(value: object) -> str:\n",
    "    \"\"\"\n",
    "    Infers the MySQL data type based on a sample value from CSV data.\n",
    "    Tries INT, FLOAT, DATETIME/DATE formats, then falls back to VARCHAR/TEXT.\n",
    "    \"\"\"\n",
    "    if value is None or (isinstance(value, str) and value.strip() == \"\"):\n",
    "        return \"TEXT\"  # Treat empty values as TEXT/nullables\n",
    "\n",
    "    # Handle actual numeric Python types (already parsed)\n",
    "    if isinstance(value, np.int64) or isinstance(value, int):\n",
    "        return \"INT\"\n",
    "    \n",
    "    elif isinstance(value, np.float64) or isinstance(value, float):\n",
    "        return \"DECIMAL(18, 6)\"\n",
    "    \n",
    "    elif isinstance(value, str):\n",
    "        val = value.strip()\n",
    "        \n",
    "        # Try INT\n",
    "        try:\n",
    "            int(val)\n",
    "            return \"INT\"\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # Try FLOAT\n",
    "        try:\n",
    "            float(val)\n",
    "            return \"DECIMAL(18, 6)\"\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # Try known datetime formats\n",
    "        datetime_formats = {\n",
    "            \"DATETIME\": [\n",
    "                \"%Y-%m-%d %H:%M:%S\"\n",
    "                ,\"%d-%m-%Y %H:%M:%S\"\n",
    "                ,\"%m/%d/%Y %H:%M:%S\"\n",
    "            ],\n",
    "            \"DATE\": [\n",
    "                \"%Y-%m-%d\"\n",
    "                ,\"%d-%m-%Y\"\n",
    "                ,\"%m/%d/%Y\"\n",
    "                ,\"%d %b %Y\"\n",
    "                ,\"%d %B %Y\"\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        for fmt in datetime_formats[\"DATETIME\"]:\n",
    "            try:\n",
    "                pd.to_datetime(val, format=fmt)\n",
    "                return \"DATETIME\"\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        for fmt in datetime_formats[\"DATE\"]:\n",
    "            try:\n",
    "                pd.to_datetime(val, format=fmt)\n",
    "                return \"DATE\"\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        # Fallback for short strings\n",
    "        return \"VARCHAR(255)\" if len(val) < 255 else \"TEXT\"\n",
    "\n",
    "\n",
    "def create_tables_from_csv(targetdirectory: str = EXTRACT_DIR ) -> None:\n",
    "    \"\"\"\n",
    "    Scans CSV files in a given directory, infers table schema, \n",
    "    and creates MySQL tables dynamically based on CSV headers and data types.\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob(os.path.join(targetdirectory, \"*.csv\"))\n",
    "    \n",
    "    # Create list of tuples [(filename, filepath)]\n",
    "    file_list = [(os.path.basename(file), file) for file in csv_files]\n",
    "    \n",
    "    conn = mysql.connector.connect(**CONN_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Table Creation Loop\n",
    "    for filename, filepath in file_list:\n",
    "        table_name = os.path.splitext(filename)[0]  # Remove .csv extension\n",
    "\n",
    "        df = pd.read_csv(filepath, nrows=1)\n",
    "\n",
    "        columns = df.columns.tolist()\n",
    "\n",
    "        inferred_types = [infer_mysql_dtype(df.iloc[0][col]) for col in columns]\n",
    "\n",
    "        columns_sql = \", \".join(f\"{col} {dtype}\" for col, dtype in zip(columns, inferred_types))\n",
    "        create_table_sql = f\" CREATE TABLE IF NOT EXISTS {DBSTART}.{table_name} ({columns_sql});\"\n",
    "        \n",
    "        cursor.execute(create_table_sql)\n",
    "        \n",
    "    #Confirm the table was created in the SQL server\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            SELECT EXISTS(\n",
    "                SELECT * FROM information_schema.tables \n",
    "                WHERE\n",
    "                    table_type = 'BASE TABLE'\n",
    "                    AND table_name = '{table_name}');\n",
    "            \"\"\"\n",
    "        )\n",
    "        table_check = cursor.fetchall()        \n",
    "        \n",
    "        try:\n",
    "            if len(table_check) == 1 & table_check[0][0] == table_name:\n",
    "                print(f\"Table `{table_name}` created successfully.\")\n",
    "        except Exception as err:\n",
    "            print(f\"Table creation unsuccessfull, Error: {err}\")\n",
    "            \n",
    "            \n",
    "    csv_files = [r\"C:\\\\Users\\\\Abunch\\\\Downloads\\\\Contoso\\\\date.csv\"]        \n",
    "    file_list = [(os.path.basename(file), file) for file in csv_files]\n",
    "    # Table Insert Loop\n",
    "    for filename, filepath in file_list:            \n",
    "        \n",
    "        table_name = os.path.splitext(filename)[0] \n",
    "\n",
    "        try:\n",
    "            #load the CSV to dataframe and index in blocks of 100 rows\n",
    "            data = pd.read_csv(filepath, chunksize=10)\n",
    "            num_chunks = sum(1 for _ in data)\n",
    "            counter = 0\n",
    "            \n",
    "            with tqdm(total=num_chunks, unit=\"chunks\", desc=f\"Loading {table_name}\") as progress_bar:\n",
    "\n",
    "                for index,chunk in enumerate(data,start=1):\n",
    "                    try:\n",
    "                        chunk.to_sql(f\"{DBSTART}.{table_name}\", conn=conn, if_exists='append', index=False, method='multi')\n",
    "                        print(f\"Chunk of data loaded into table `{table_name}` successfully.\")\n",
    "                        progress_bar.update(1)\n",
    "                        counter += 1\n",
    "                    \n",
    "                    except Exception as err:\n",
    "                        print(f\"Error loading chunk # {counter} into table `{table_name}`: {err}\")\n",
    "                        break\n",
    "                        \n",
    "            \n",
    "                # Load data into the table\n",
    "                df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "                print(f\"Data loaded into table `{table_name}` successfully.\")\n",
    "            \n",
    "    \n",
    "        except Exception as err:\n",
    "            print(f\"Error loading data into table `{table_name}`: {err}\")     \n",
    "               \n",
    "    # Close DB connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def create_table(databse_name: str, table_name: str, columns: Dict[str, str]) -> None:\n",
    "    \"\"\"\n",
    "    Creates a new MySQL table with the specified columns.\n",
    "\n",
    "    :param table_name: The name of the table to create.\n",
    "    :param columns: A dictionary where keys are column names and values are MySQL data types.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = mysql.connector.connect(**CONN_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        columns_sql = \", \".join(f\"`{col}` {dtype}\" for col, dtype in columns.items())\n",
    "\n",
    "        create_table_sql = f\"CREATE TABLE IF NOT EXISTS `{databse_name}.{table_name}` ({columns_sql});\"\n",
    "\n",
    "        cursor.execute(create_table_sql)\n",
    "        \n",
    "         #Confirm the table was created in the SQL server\n",
    "        cursor.execute(\n",
    "            f\"\"\"\n",
    "            SELECT EXISTS(\n",
    "                SELECT * FROM information_schema.tables \n",
    "                WHERE\n",
    "                        table_type = 'BASE TABLE'\n",
    "                        AND table_name = '{table_name}');\n",
    "            \"\"\"\n",
    "        )\n",
    "        table_check = cursor.fetchall()        \n",
    "        try:\n",
    "            if len(table_check) == 1 & table_check[0][0] == table_name:\n",
    "                print(f\"Table `{table_name}` created successfully.\")\n",
    "        except Exception as err:\n",
    "            print(f\"Table not created successfully, Error: {err}\")\n",
    "            \n",
    "\n",
    "        # Close DB connection\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"Error: {err}\")\n",
    "\n",
    "\n",
    "# def load_to_table(table_name : str) -> None:\n",
    "        \n",
    "#     try:\n",
    "#         #load the CSV to dataframe and index in blocks of 100 rows\n",
    "#         data_df = pd.read_csv(filepath, chunksize=1000)\n",
    "#         # find the number of chunks\n",
    "#         num_chunks = sum(1 for _ in data_df)\n",
    "#         counter = 0\n",
    "        \n",
    "#         with tqdm(total=num_chunks, unit=\"chunks\", desc=f\"Loading {table_name}\") as progress_bar:\n",
    "\n",
    "#             for chunk in data_df:\n",
    "#                 try:\n",
    "#                     chunk.to_sql(f\"{DBSTART}.{table_name}\", conn, if_exists='append', index=False)\n",
    "#                     print(f\"Chunk of data loaded into table `{table_name}` successfully.\")\n",
    "#                     counter += 1\n",
    "                \n",
    "#                 except Exception as err:\n",
    "#                     print(f\"Error loading chunk # {counter} into table `{table_name}`: {err}\")\n",
    "#                     break\n",
    "                    \n",
    "        \n",
    "#             # Load data into the table\n",
    "#             df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "#             print(f\"Data loaded into table `{table_name}` successfully.\")\n",
    "        \n",
    "    \n",
    "#     except Exception as err:\n",
    "#         print(f\"Error loading data into table `{table_name}`: {err}\")\n",
    "\n",
    "# download_file(CONTOSO_DOWNLOAD_LINK, CONTOSO_FILENAME) # works\n",
    "# extract_archive(CONTOSO_FILENAME) # works\n",
    "# create_database(DBSTART) # works\n",
    "create_tables_from_csv(EXTRACT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table `currencyexchange` with SQL:  CREATE TABLE IF NOT EXISTS Contoso.currencyexchange (Date DATE, FromCurrency VARCHAR(255), ToCurrency VARCHAR(255), Exchange DECIMAL(18, 6));\n",
      "Creating table `customer` with SQL:  CREATE TABLE IF NOT EXISTS Contoso.customer (CustomerKey INT, GeoAreaKey INT, StartDT DATE, EndDT DATE, Continent VARCHAR(255), Gender VARCHAR(255), Title VARCHAR(255), GivenName VARCHAR(255), MiddleInitial VARCHAR(255), Surname VARCHAR(255), StreetAddress VARCHAR(255), City VARCHAR(255), State VARCHAR(255), StateFull VARCHAR(255), ZipCode INT, Country VARCHAR(255), CountryFull VARCHAR(255), Birthday DATE, Age INT, Occupation VARCHAR(255), Company VARCHAR(255), Vehicle VARCHAR(255), Latitude DECIMAL(18, 6), Longitude DECIMAL(18, 6));\n",
      "Creating table `date` with SQL:  CREATE TABLE IF NOT EXISTS Contoso.date (Date DATE, DateKey INT, Year INT, YearQuarter VARCHAR(255), YearQuarterNumber INT, Quarter VARCHAR(255), YearMonth VARCHAR(255), YearMonthShort VARCHAR(255), YearMonthNumber INT, Month VARCHAR(255), MonthShort VARCHAR(255), MonthNumber INT, DayofWeek VARCHAR(255), DayofWeekShort VARCHAR(255), DayofWeekNumber INT, WorkingDay INT, WorkingDayNumber INT);\n",
      "Creating table `orderrows` with SQL:  CREATE TABLE IF NOT EXISTS Contoso.orderrows (OrderKey DECIMAL(18, 6), LineNumber DECIMAL(18, 6), ProductKey DECIMAL(18, 6), Quantity DECIMAL(18, 6), UnitPrice DECIMAL(18, 6), NetPrice DECIMAL(18, 6), UnitCost DECIMAL(18, 6));\n",
      "Creating table `orders` with SQL:  CREATE TABLE IF NOT EXISTS Contoso.orders (OrderKey INT, CustomerKey INT, StoreKey INT, OrderDate DATE, DeliveryDate DATE, CurrencyCode VARCHAR(255));\n",
      "Creating table `product` with SQL:  CREATE TABLE IF NOT EXISTS Contoso.product (ProductKey INT, ProductCode INT, ProductName VARCHAR(255), Manufacturer VARCHAR(255), Brand VARCHAR(255), Color VARCHAR(255), WeightUnit VARCHAR(255), Weight DECIMAL(18, 6), Cost DECIMAL(18, 6), Price DECIMAL(18, 6), CategoryKey INT, CategoryName VARCHAR(255), SubCategoryKey INT, SubCategoryName VARCHAR(255));\n",
      "Creating table `sales` with SQL:  CREATE TABLE IF NOT EXISTS Contoso.sales (OrderKey INT, LineNumber INT, OrderDate DATE, DeliveryDate DATE, CustomerKey INT, StoreKey INT, ProductKey INT, Quantity INT, UnitPrice DECIMAL(18, 6), NetPrice DECIMAL(18, 6), UnitCost DECIMAL(18, 6), CurrencyCode VARCHAR(255), ExchangeRate DECIMAL(18, 6));\n",
      "Creating table `store` with SQL:  CREATE TABLE IF NOT EXISTS Contoso.store (StoreKey INT, StoreCode INT, GeoAreaKey INT, CountryCode VARCHAR(255), CountryName VARCHAR(255), State VARCHAR(255), OpenDate DATE, CloseDate DECIMAL(18, 6), Description VARCHAR(255), SquareMeters INT, Status DECIMAL(18, 6));\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "csv_files = [r\"C:\\\\Users\\\\Abunch\\\\Downloads\\\\Contoso\\\\date.csv\"]        \n",
    "file_list = [(os.path.basename(file), file) for file in csv_files]\n",
    "# Table Insert Loop\n",
    "for filename, filepath in file_list:            \n",
    "    \n",
    "    table_name = os.path.splitext(filename)[0] \n",
    "\n",
    "    try:\n",
    "        #load the CSV to dataframe and index in blocks of 100 rows\n",
    "        data = pd.read_csv(filepath, chunksize=10)\n",
    "        num_chunks = sum(1 for _ in data)\n",
    "        counter = 0\n",
    "        \n",
    "        with tqdm(total=num_chunks, unit=\"chunks\", desc=f\"Loading {table_name}\") as progress_bar:\n",
    "\n",
    "            for index,chunk in enumerate(data,start=1):\n",
    "                try:\n",
    "                   \n",
    "                    print(f\"Chunk of data loaded into table `{table_name}` successfully.\")\n",
    "                    progress_bar.update(1)\n",
    "                    counter += 1\n",
    "                \n",
    "                except Exception as err:\n",
    "                    print(f\"Error loading chunk # {counter} into table `{table_name}`: {err}\")\n",
    "                    break\n",
    "                    \n",
    "        \n",
    "\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"Error loading data into table `{table_name}`: {err}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # confirm the tables were created in the SQL server\n",
    "# conn = mysql.connector.connect(**CONN_CONFIG)\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# cursor.execute(\n",
    "#     f\"\"\"\n",
    "#     SELECT table_name \n",
    "#     FROM information_schema.tables \n",
    "#     WHERE table_schema = '{DBSTART}';\n",
    "#     \"\"\"\n",
    "# )\n",
    "# table_list = cursor.fetchall()\n",
    "\n",
    "# # glob the extract directory for all files\n",
    "# file_list = glob.glob(os.path.join(EXTRACT_DIR, \"*.csv\"))    \n",
    "\n",
    "    \n",
    "# # only if all tables in the filelist are created in the SQL server, then delete the files\n",
    "# for file in file_list:\n",
    "#     table_name = os.path.splitext(file)[0]  # Remove .csv extension\n",
    "#     if table_name in table_list:\n",
    "#         print(f\"Deleting {file} from {EXTRACT_DIR}\")\n",
    "#         os.remove(os.path.join(EXTRACT_DIR, file))\n",
    "#     else:\n",
    "#         print(f\"File {file} not found in SQL server, will not delete.\")\n",
    "        \n",
    "# # check if all files were deleted\n",
    "# for file in file_list:\n",
    "#     if os.path.exists(os.path.join(EXTRACT_DIR, file)):\n",
    "#         print(f\"File {file} still exists in {EXTRACT_DIR}\")\n",
    "#         # attempt to create the table again 2 more times, else exit the script\n",
    "#         counter = 0\n",
    "#         while counter < 2:\n",
    "#             table_name = os.path.splitext(file)[0]\n",
    "#             columns = []\n",
    "#             df = pd.read_csv(file, nrows=2)\n",
    "#             columns = df.columns.tolist()\n",
    "#             inferred_types = [infer_mysql_dtype(df.iloc[0][col]) for col in columns]\n",
    "#             columns = {col: dtype for col, dtype in zip(columns, inferred_types)}\n",
    "#             create_table(DBSTART, file, columns=columns)\n",
    "#             # confirm the table was created in the SQL server\n",
    "#             cursor.execute(\n",
    "#                 f\"\"\"\n",
    "#                 SELECT EXISTS(\n",
    "#                     SELECT * \n",
    "#                     FROM information_schema.tables \n",
    "#                     WHERE\n",
    "#                         table_type = 'BASE TABLE'\n",
    "#                         AND table_name = '{table_name}');\n",
    "#                 \"\"\"\n",
    "#             )\n",
    "#             table_check = cursor.fetchall()\n",
    "#             try:\n",
    "#                 if len(table_check) == 1 & table_check[0][0] == table_name:\n",
    "#                     print(f\"Table `{table_name}` created successfully.\")\n",
    "#                     os.remove(os.path.join(EXTRACT_DIR, file))\n",
    "#                     break\n",
    "#             except Exception as err:\n",
    "#                 print(f\"Table not created successfully, Error: {err}\")\n",
    "#                 counter += 1\n",
    "#                 if counter == 2:\n",
    "#                     print(f\"File {file} still exists in {EXTRACT_DIR}, exiting script.\")\n",
    "#                     exit()\n",
    "#                 else:\n",
    "#                     print(f\"Retrying to create table {table_name}...\")\n",
    "#     else:\n",
    "#         print(f\"File {file} deleted from {EXTRACT_DIR}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
